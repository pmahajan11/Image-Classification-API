{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import required packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport time\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model\nfrom tqdm import tqdm\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T22:57:48.248145Z","iopub.execute_input":"2022-06-07T22:57:48.248906Z","iopub.status.idle":"2022-06-07T22:57:50.588541Z","shell.execute_reply.started":"2022-06-07T22:57:48.248798Z","shell.execute_reply":"2022-06-07T22:57:50.587396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdir=r'../input/3-kinds-of-pneumonia/Curated X-Ray Dataset'\nworking_dir=r'./'\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\nhistpath=os.path.join(working_dir, 'hist')# store equalized histogram images in this directory\nif os.path.isdir(histpath):\n    shutil.rmtree(histpath) # start with an empty directory\nos.mkdir(histpath) # create the directory\nclasslist=os.listdir(sdir) # iteratethrough the classes\nfor klass in classlist:\n    print ('processing class ', klass)\n    classpath=os.path.join(sdir, klass)\n    dest_classpath=os.path.join(histpath, klass)\n    os.mkdir(dest_classpath)# make the class directories\n    flist=os.listdir(classpath)\n    sampled_list=np.random.choice(flist, size=1200, replace=False) # use only 1200 images from each class\n    for f in tqdm(sampled_list):\n        fpath=os.path.join(classpath,f)\n        dest_fpath=os.path.join(dest_classpath,f)\n        img = cv2.imread(fpath,0) # read in the image\n        cl1 = clahe.apply(img) # balance the image histogram\n        cv2.imwrite(dest_fpath, cl1) # save the balanced image\n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-07T22:58:09.824698Z","iopub.execute_input":"2022-06-07T22:58:09.82511Z","iopub.status.idle":"2022-06-07T23:01:26.333781Z","shell.execute_reply.started":"2022-06-07T22:58:09.825076Z","shell.execute_reply":"2022-06-07T23:01:26.332852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Read in images and create a dataframe of image paths and class labels","metadata":{}},{"cell_type":"code","source":"sdir=histpath\nclasslist=sorted(os.listdir(sdir))\nfilepaths = []\nlabels=[] \nfor klass in classlist:\n    classpath=os.path.join(sdir, klass)\n    flist=sorted(os.listdir(classpath))\n    for f in flist:\n        fpath=os.path.join(classpath,f)\n        filepaths.append(fpath)\n        labels.append(klass)\nFseries=pd.Series(filepaths, name='filepaths')\nLseries=pd.Series(labels, name='labels')        \ndf=pd.concat([Fseries, Lseries], axis=1)\ntrain_df, dummy_df=train_test_split(df, train_size=.9, shuffle=True, random_state=123, stratify=df['labels'])\nvalid_df, test_df= train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])     \nprint('train_df lenght: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n# get the number of classes and the images count for each class in train_df\nclasses=sorted(list(train_df['labels'].unique()))\nclass_count = len(classes)\nprint('The number of classes in the dataset is: ', class_count)\ngroups=train_df.groupby('labels')\nprint('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\ncountlist=[]\nclasslist=[]\nfor label in sorted(list(train_df['labels'].unique())):\n    group=groups.get_group(label)\n    countlist.append(len(group))\n    classlist.append(label)\n    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n\n# get the classes with the minimum and maximum number of train images\nmax_value=np.max(countlist)\nmax_index=countlist.index(max_value)\nmax_class=classlist[max_index]\nmin_value=np.min(countlist)\nmin_index=countlist.index(min_value)\nmin_class=classlist[min_index]\nprint(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n# lets get the average height and width of a sample of the train images\nht=0\nwt=0\n# select 100 random samples of train_df\ntrain_df_sample=train_df.sample(n=100, random_state=123,axis=0)\nfor i in range (len(train_df_sample)):\n    fpath=train_df_sample['filepaths'].iloc[i]\n    img=plt.imread(fpath)\n    shape=img.shape\n    ht += shape[0]\n    wt += shape[1]\nprint('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:02:02.204898Z","iopub.execute_input":"2022-06-07T23:02:02.205423Z","iopub.status.idle":"2022-06-07T23:02:03.371089Z","shell.execute_reply.started":"2022-06-07T23:02:02.205385Z","shell.execute_reply":"2022-06-07T23:02:03.370215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Create the train_gen, test_gen final_test_gen and valid_gen","metadata":{}},{"cell_type":"code","source":"working_dir=r'./'\nimg_size=(300, 375)\nprint(img_size)\nbatch_size=30 # We will use and EfficientetB3 model, with image size of (200, 250) this size should not cause resource error\ntrgen=ImageDataGenerator(horizontal_flip=True,rotation_range=20, width_shift_range=.2,\n                                  height_shift_range=.2, zoom_range=.2 )\nt_and_v_gen=ImageDataGenerator()\nmsg='{0:70s} for train generator'.format(' ')\nprint(msg, '\\r', end='') # prints over on the same line\ntrain_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n                                   class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\nmsg='{0:70s} for valid generator'.format(' ')\nprint(msg, '\\r', end='') # prints over on the same line\nvalid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n# for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n# this insures that we go through all the sample in the test set exactly once.\nlength=len(test_df)\ntest_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \ntest_steps=int(length/test_batch_size)\nmsg='{0:70s} for test generator'.format(' ')\nprint(msg, '\\r', end='') # prints over on the same line\ntest_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,\n                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n# from the generator we can get information we will need later\nclasses=list(train_gen.class_indices.keys())\nclass_indices=list(train_gen.class_indices.values())\nclass_count=len(classes)\nlabels=test_gen.labels\nprint ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:02:06.444111Z","iopub.execute_input":"2022-06-07T23:02:06.444512Z","iopub.status.idle":"2022-06-07T23:02:06.520926Z","shell.execute_reply.started":"2022-06-07T23:02:06.444482Z","shell.execute_reply":"2022-06-07T23:02:06.519751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Example training images","metadata":{}},{"cell_type":"code","source":"def show_image_samples(gen ):\n    t_dict=gen.class_indices\n    classes=list(t_dict.keys())    \n    images,labels=next(gen) # get a sample batch from the generator \n    plt.figure(figsize=(20, 20))\n    length=len(labels)\n    if length<25:   #show maximum of 25 images\n        r=length\n    else:\n        r=25\n    for i in range(r):        \n        plt.subplot(5, 5, i + 1)\n        image=images[i] /255       \n        plt.imshow(image)\n        index=np.argmax(labels[i])\n        class_name=classes[index]\n        plt.title(class_name, color='blue', fontsize=12)\n        plt.axis('off')\n    plt.show()\n    \nshow_image_samples(train_gen )","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:02:10.646625Z","iopub.execute_input":"2022-06-07T23:02:10.647648Z","iopub.status.idle":"2022-06-07T23:02:14.33836Z","shell.execute_reply.started":"2022-06-07T23:02:10.647585Z","shell.execute_reply":"2022-06-07T23:02:14.336854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Transfer learning with EfficientNetB3","metadata":{}},{"cell_type":"code","source":"img_shape=(img_size[0], img_size[1], 3)\nmodel_name='EfficientNetB3'\nbase_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n# Note you are always told NOT to make the base model trainable initially- that is WRONG you get better results leaving it trainable\nbase_model.trainable=True\nx=base_model.output\nx=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\nx=Dropout(rate=.4, seed=123)(x)       \noutput=Dense(class_count, activation='softmax')(x)\nmodel=Model(inputs=base_model.input, outputs=output)\nlr=.001 # start with this learning rate\nmodel.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy']) ","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:05:19.172528Z","iopub.execute_input":"2022-06-07T23:05:19.173485Z","iopub.status.idle":"2022-06-07T23:05:22.08979Z","shell.execute_reply.started":"2022-06-07T23:05:19.173444Z","shell.execute_reply":"2022-06-07T23:05:22.088929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:05:26.079308Z","iopub.execute_input":"2022-06-07T23:05:26.080091Z","iopub.status.idle":"2022-06-07T23:05:26.176529Z","shell.execute_reply.started":"2022-06-07T23:05:26.080043Z","shell.execute_reply":"2022-06-07T23:05:26.175611Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom Keras callback\n\nclass ASK(keras.callbacks.Callback):\n    def __init__ (self, model, epochs,  ask_epoch): # initialization of the callback\n        super(ASK, self).__init__()\n        self.model=model               \n        self.ask_epoch=ask_epoch\n        self.epochs=epochs\n        self.ask=True # if True query the user on a specified epoch\n        \n    def on_train_begin(self, logs=None): # this runs on the beginning of training\n        if self.ask_epoch == 0: \n            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n            self.ask_epoch=1\n        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n            self.ask=False # do not query the user\n        if self.epochs == 1:\n            self.ask=False # running only for 1 epoch so do not query user\n        else:\n            print('Training will proceed until epoch', ask_epoch,' then you will be asked to') \n            print(' enter H to halt training or enter an integer for how many more epochs to run then be asked again')  \n        self.start_time= time.time() # set the time at which training started\n        \n    def on_train_end(self, logs=None):   # runs at the end of training     \n        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n        hours = tr_duration // 3600\n        minutes = (tr_duration - (hours * 3600)) // 60\n        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n        print (msg, flush=True) # print out training duration time\n        \n    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n        if self.ask: # are the conditions right to query the user?\n            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n                print('\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again')\n                ans=input()\n                \n                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n                    print ('you entered ', ans, ' Training halted on epoch ', epoch+1, ' due to user input\\n', flush=True)\n                    self.model.stop_training = True # halt training\n                else: # user wants to continue training\n                    self.ask_epoch += int(ans)\n                    if self.ask_epoch > self.epochs:\n                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n                    else:\n                        print ('you entered ', ans, ' Training will continue to epoch ', self.ask_epoch, flush=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:05:32.505213Z","iopub.execute_input":"2022-06-07T23:05:32.505618Z","iopub.status.idle":"2022-06-07T23:05:32.521516Z","shell.execute_reply.started":"2022-06-07T23:05:32.505586Z","shell.execute_reply":"2022-06-07T23:05:32.520576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate custom callback and create 2 callbacks to control learning rate and early stop\n\nepochs=50\nask_epoch=10\nask=ASK(model, epochs,  ask_epoch)\nrlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\nestop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, verbose=1,restore_best_weights=True)\ncallbacks=[rlronp, estop, ask]","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:05:34.665392Z","iopub.execute_input":"2022-06-07T23:05:34.66577Z","iopub.status.idle":"2022-06-07T23:05:34.672214Z","shell.execute_reply.started":"2022-06-07T23:05:34.665738Z","shell.execute_reply":"2022-06-07T23:05:34.671013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Train the model","metadata":{}},{"cell_type":"code","source":"print(f\"Number of GPUs available: {len(tf.config.list_physical_devices('GPU'))}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:05:38.219451Z","iopub.execute_input":"2022-06-07T23:05:38.219856Z","iopub.status.idle":"2022-06-07T23:05:38.22478Z","shell.execute_reply.started":"2022-06-07T23:05:38.219822Z","shell.execute_reply":"2022-06-07T23:05:38.224011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(x=train_gen,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=valid_gen,\n               validation_steps=None,  shuffle=False,  initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T23:05:39.29484Z","iopub.execute_input":"2022-06-07T23:05:39.295308Z","iopub.status.idle":"2022-06-08T00:32:52.132061Z","shell.execute_reply.started":"2022-06-07T23:05:39.295271Z","shell.execute_reply":"2022-06-08T00:32:52.126405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tr_plot(tr_data, start_epoch):\n    #Plot the training and validation data\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout    \n    plt.show()\n    \ntr_plot(history,0)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:35:39.278412Z","iopub.execute_input":"2022-06-08T00:35:39.279395Z","iopub.status.idle":"2022-06-08T00:35:48.835573Z","shell.execute_reply.started":"2022-06-08T00:35:39.279359Z","shell.execute_reply":"2022-06-08T00:35:48.834794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Make Predictions on the test set","metadata":{}},{"cell_type":"code","source":"def predictor(test_gen, test_steps):\n    y_pred= []\n    y_true=test_gen.labels\n    classes=list(train_gen.class_indices.keys())\n    class_count=len(classes)\n    errors=0\n    preds=model.predict(test_gen, steps=test_steps, verbose=1) # predict on the test set\n    tests=len(preds)\n    for i, p in enumerate(preds):\n            pred_index=np.argmax(p)         \n            true_index=test_gen.labels[i]  # labels are integer values\n            if pred_index != true_index: # a misclassification has occurred                                           \n                errors=errors + 1\n            y_pred.append(pred_index)\n    acc=( 1-errors/tests) * 100\n    print(f'there were {errors} errors in {tests} tests for an accuracy of {acc:6.2f}')\n    ypred=np.array(y_pred)\n    ytrue=np.array(y_true)\n    if class_count <=30:\n        cm = confusion_matrix(ytrue, ypred )\n        # plot the confusion matrix\n        plt.figure(figsize=(12, 8))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix\")\n        plt.show()\n    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create classification report\n    print(\"Classification Report:\\n----------------------\\n\", clr)\n    return errors, tests\nerrors, tests=predictor(test_gen, test_steps)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:36:15.803719Z","iopub.execute_input":"2022-06-08T00:36:15.80415Z","iopub.status.idle":"2022-06-08T00:36:23.245559Z","shell.execute_reply.started":"2022-06-08T00:36:15.804117Z","shell.execute_reply":"2022-06-08T00:36:23.244674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Save the model and model weights","metadata":{}},{"cell_type":"code","source":"subject='pneumonia-model'\nsubject2='pneumonia-model-weights'\nacc=str(( 1-errors/tests) * 100)\nindex=acc.rfind('.')\nacc=acc[:index + 3]\nsave_id= subject + '-acc-' + str(acc) + '.h5'\nsave_id2= subject2 + '-acc-' + str(acc) + '.h5'\nmodel_save_loc=os.path.join(working_dir, save_id)\nmodel.save(model_save_loc)\nmodel_save_loc2=os.path.join(working_dir, save_id2)\nmodel.save_weights(model_save_loc2)\nprint ('model was saved as ' , model_save_loc ) \n   ","metadata":{"execution":{"iopub.status.busy":"2022-06-08T00:41:22.287682Z","iopub.execute_input":"2022-06-08T00:41:22.288074Z","iopub.status.idle":"2022-06-08T00:41:24.584098Z","shell.execute_reply.started":"2022-06-08T00:41:22.288041Z","shell.execute_reply":"2022-06-08T00:41:24.583063Z"},"trusted":true},"execution_count":null,"outputs":[]}]}